import { AuthService } from '@/services/authService';

/**
 * API mock pour simuler la r√©ception des rapports LLMO
 * En attendant l'impl√©mentation de l'API r√©elle
 */

// Configuration pour le d√©veloppement
const isDevelopment = import.meta.env.DEV;
const API_BASE_URL = import.meta.env.VITE_API_BASE_URL || 'https://api.virail.studio';

console.log('üîß Configuration API:', {
  isDevelopment,
  API_BASE_URL,
  NODE_ENV: import.meta.env.MODE
});

/**
 * Intercepteur pour ajouter automatiquement l'authentification aux requ√™tes
 */
async function fetchWithAuth(url: string, options: RequestInit = {}): Promise<Response> {
  // Si l'URL est pour l'authentification, utiliser fetch normal
  if (url.includes('/auth/')) {
    return fetch(url, options);
  }

  // Pour les autres requ√™tes, utiliser l'intercepteur d'authentification
  return AuthService.makeAuthenticatedRequest(url, options);
}

export interface ReportResponse {
  id: string;
  url: string;
  status: 'completed' | 'processing' | 'failed';
  createdAt: string;
  duration: number;
  rawData: string;
  metadata: {
    llmsUsed: string[];
    totalAnalyses: number;
    completionRate: number;
    score?: number | null;
  };
}

export interface Report {
  id: number;
  url: string;
  status: string;
  report_path: string;
  report_filename: string;
  report_size: number;
  position_produit_analyse: number;
  score_produit_analyse: number | null;
  created_at: string;
  updated_at: string;
}

export interface AnalysisModule {
  [key: string]: any;
}

export interface Analysis {
  llm_name: string;
  statut: string;
  duree: number;
  erreurs_modules: string[];
  created_at: string;
  modules: {
    perception: AnalysisModule;
    audience: AnalysisModule;
    recommandation: AnalysisModule;
    valeur: AnalysisModule;
    semantique: AnalysisModule;
    audit_geo?: AnalysisModule;
    synthese: AnalysisModule;
  }
}

export interface FullReportData {
  report: Report;
  analyses: Analysis[];
}

/**
 * R√©cup√®re un rapport LLMO complet par ID
 */
export async function fetchReport(reportId: string): Promise<FullReportData | null> {
  try {
    const response = await fetchWithAuth(`${API_BASE_URL}/llmo/reports/${reportId}`);

    if (!response.ok) {
      let errorMessage = `Erreur lors du chargement du rapport: ${response.status} ${response.statusText}`;

      // Gestion sp√©cifique des erreurs courantes
      switch (response.status) {
        case 404:
          errorMessage = 'Rapport non trouv√©. Il a peut-√™tre √©t√© supprim√©.';
          break;
        case 403:
          errorMessage = 'Acc√®s refus√©. Vous n\'avez pas les permissions pour voir ce rapport.';
          break;
        case 422:
          errorMessage = 'Erreur de traitement du rapport. Le contenu analys√© peut √™tre probl√©matique.';
          break;
        case 429:
          errorMessage = 'Trop de requ√™tes. Veuillez patienter quelques instants.';
          break;
        case 500:
          errorMessage = 'Erreur serveur. Le service est temporairement indisponible.';
          break;
        case 502:
        case 503:
        case 504:
          errorMessage = 'Service indisponible. Veuillez r√©essayer plus tard.';
          break;
      }

      console.error(errorMessage);
      throw new Error(errorMessage);
    }

    const data: FullReportData = await response.json();
    return data;

  } catch (error) {
    console.error('Erreur lors de la r√©cup√©ration du rapport:', error);
    return null;
  }
}

/**
 * Lance une nouvelle analyse LLMO avec deux appels API en parall√®le pour optimiser les performances
 */
export async function startAnalysis(url: string): Promise<{ reportId: string; status: string; metadata?: any } | null> {
  try {
    console.log('üöÄ Lancement de l\'analyse pour:', url);

    // Faire deux appels API en parall√®le pour optimiser les performances
    const [analysisResponse, metadataResponse] = await Promise.all([
      // Premier appel : Lancer l'analyse principale
      fetchWithAuth(`${API_BASE_URL}/analyze`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ url }),
      }),
      
      // Deuxi√®me appel : R√©cup√©rer les m√©tadonn√©es ou configurations
      fetchWithAuth(`${API_BASE_URL}/analyze/config`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ 
          url,
          get_metadata: true,
          optimization_level: 'high' 
        }),
      })
    ]);

    // V√©rifier que les deux r√©ponses sont OK
    if (!analysisResponse.ok) {
      const errorData = await analysisResponse.json().catch(() => ({ message: 'Erreur lors de l\'analyse principale' }));
      throw new Error(errorData.message || `Erreur HTTP analyse: ${analysisResponse.status}`);
    }

    if (!metadataResponse.ok) {
      console.warn('‚ö†Ô∏è M√©tadonn√©es non disponibles, continuons avec l\'analyse principale');
    }

    // Traiter les r√©ponses
    const analysisData = await analysisResponse.json();
    const metadataData = metadataResponse.ok ? await metadataResponse.json() : null;

    console.log('‚úÖ R√©ponse de l\'API startAnalysis:', analysisData);
    console.log('üìä M√©tadonn√©es re√ßues:', metadataData);
    
    // Adapter la r√©ponse selon le format de votre API
    const result = {
      reportId: analysisData.id || analysisData.reportId || analysisData.analysis_id || `analysis-${Date.now()}`,
      status: analysisData.status || 'processing',
      metadata: metadataData || null
    };

    console.log('üìä Analyse cr√©√©e avec optimisations:', result);
    return result;
    
  } catch (error) {
    console.error('‚ùå Erreur lors du lancement de l\'analyse optimis√©e:', error);
    return null;
  }
}

/**
 * Lance une nouvelle analyse LLMO avec deux appels API s√©quentiels 
 * (le deuxi√®me appel d√©pend du premier)
 */
export async function startAnalysisSequential(
  url: string, 
  options: { model?: string } = {}
): Promise<{ reportId: string; status: string; optimizationResults?: any } | null> {
  try {
    const { model = 'gpt-4o' } = options;
    console.log('üöÄ Lancement de l\'analyse s√©quentielle pour:', url, 'avec mod√®le:', model);

    // Premier appel : Lancer l'analyse principale
    console.log('üìä √âtape 1: Lancement de l\'analyse LLMO principale...');
    const analysisResponse = await fetchWithAuth(`${API_BASE_URL}/analyze`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ url }),
    });

    if (!analysisResponse.ok) {
      const errorData = await analysisResponse.json().catch(() => ({ message: 'Erreur lors de l\'analyse principale' }));
      throw new Error(errorData.message || `Erreur HTTP analyse: ${analysisResponse.status}`);
    }

    const analysisData = await analysisResponse.json();
    console.log('‚úÖ Premi√®re analyse termin√©e:', analysisData);

    // Deuxi√®me appel : Optimisation bas√©e sur les r√©sultats du premier
    console.log('üéØ √âtape 2: Lancement de l\'optimisation...');
    let optimizationData = null;
    
    // Essayer plusieurs endpoints d'optimisation
    const optimizationEndpoints = [
      `${API_BASE_URL}/optimize`,
      `${API_BASE_URL}/analyze/optimize`, 
      `${API_BASE_URL}/analyze/enhance`
    ];
    
    for (const endpoint of optimizationEndpoints) {
      try {
        console.log(`üîÑ Tentative d'optimisation via: ${endpoint}`);
        const optimizationResponse = await fetchWithAuth(endpoint, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({ 
            url,
            model,
            analysis_id: analysisData.id || analysisData.reportId || analysisData.analysis_id
          }),
        });

        if (optimizationResponse.ok) {
          optimizationData = await optimizationResponse.json();
          console.log('‚úÖ Optimisation r√©ussie via:', endpoint, optimizationData);
          break;
        } else {
          console.log(`‚ö†Ô∏è √âchec de l'optimisation via ${endpoint}:`, optimizationResponse.status);
        }
      } catch (error) {
        console.log(`‚ùå Erreur lors de l'optimisation via ${endpoint}:`, error);
      }
    }
    
    if (!optimizationData) {
      console.warn('‚ö†Ô∏è Aucune optimisation n\'a r√©ussi, r√©sultats de base conserv√©s');
    }
    
    // Retourner les r√©sultats combin√©s
    const result = {
      reportId: analysisData.id || analysisData.reportId || analysisData.analysis_id || `analysis-${Date.now()}`,
      status: analysisData.status || 'processing',
      optimizationResults: optimizationData
    };

    console.log('üìä Analyse s√©quentielle termin√©e:', result);
    return result;
    
  } catch (error) {
    console.error('‚ùå Erreur lors de l\'analyse s√©quentielle:', error);
    return null;
  }
}

/**
 * Lance une nouvelle analyse sur le port 8001 avec les param√®tres √©tendus
 */
export async function startAnalysisExtended(
  url: string,
  options: {
    min_score?: number;
    min_mentions?: number;
    models?: string[];
    include_raw?: boolean;
  } = {}
): Promise<{ reportId: string; status: string; data?: any } | null> {
  try {
    const {
      min_score = 0.3,
      min_mentions = 1,
      models = ['gpt-5', 'claude-4-sonnet', 'gemini-2.5-pro'],
      include_raw = false
    } = options;

    console.log('üöÄ Lancement de l\'analyse √©tendue pour:', url, 'avec options:', options);

    const analysisResponse = await fetchWithAuth(`${API_BASE_URL}/analyze`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        url,
        min_score,
        min_mentions,
        models,
        include_raw
      }),
    });

    if (!analysisResponse.ok) {
      const errorData = await analysisResponse.json().catch(() => ({ message: 'Erreur lors de l\'analyse √©tendue' }));
      throw new Error(errorData.message || `Erreur HTTP analyse √©tendue: ${analysisResponse.status}`);
    }

    const analysisData = await analysisResponse.json();
    console.log('‚úÖ Analyse √©tendue termin√©e:', analysisData);
    
    const result = {
      reportId: analysisData.id || analysisData.reportId || analysisData.analysis_id || `analysis-${Date.now()}`,
      status: analysisData.status || 'processing',
      data: analysisData
    };

    console.log('üìä Analyse √©tendue cr√©√©e:', result);
    return result;
    
  } catch (error) {
    console.error('‚ùå Erreur lors de l\'analyse √©tendue:', error);
    return null;
  }
}

/**
 * Lance une nouvelle analyse LLMO simple (sans optimisation)
 * Version de fallback si l'optimisation n'est pas disponible
 */
export async function startAnalysisSimple(
  url: string, 
  options: { model?: string } = {}
): Promise<{ reportId: string; status: string } | null> {
  try {
    const { model = 'gpt-4o' } = options;
    console.log('üöÄ Lancement de l\'analyse simple pour:', url, 'avec mod√®le:', model);

    // Appel unique : Lancer l'analyse principale
    const analysisResponse = await fetchWithAuth(`${API_BASE_URL}/analyze`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ 
        url,
        model,
        optimization_level: 'basic' // Indiquer que c'est une analyse simple
      }),
    });

    if (!analysisResponse.ok) {
      const errorData = await analysisResponse.json().catch(() => ({ message: 'Erreur lors de l\'analyse' }));
      throw new Error(errorData.message || `Erreur HTTP analyse: ${analysisResponse.status}`);
    }

    const analysisData = await analysisResponse.json();
    console.log('‚úÖ Analyse simple termin√©e:', analysisData);
    
    const result = {
      reportId: analysisData.id || analysisData.reportId || analysisData.analysis_id || `analysis-${Date.now()}`,
      status: analysisData.status || 'processing'
    };

    console.log('üìä Analyse simple cr√©√©e:', result);
    return result;
    
  } catch (error) {
    console.error('‚ùå Erreur lors de l\'analyse simple:', error);
    return null;
  }
}

/**
 * Simule la v√©rification du statut d'une analyse en cours
 */
export async function checkAnalysisStatus(reportId: string): Promise<{ status: string; progress: number } | null> {
  try {
    // Simuler un d√©lai
    await new Promise(resolve => setTimeout(resolve, 200));

    // Simuler une progression
    const progress = Math.min(100, Math.random() * 100);
    const status = progress >= 100 ? 'completed' : 'processing';

    return {
      status,
      progress
    };
  } catch (error) {
    console.error('Erreur lors de la v√©rification du statut:', error);
    return null;
  }
}

/**
 * G√©n√®re des donn√©es de rapport mock pour d'autres sites
 */
function generateMockReportData(domain: string): string {
  return `# RAPPORT D'ANALYSE LLMO POUR : https://www.${domain}
==========================================================

## ANALYSES D√âTAILL√âES PAR LLM
========================================

### Analyse par : gpt-4o
**Statut :** Termin√©e avec succ√®s (Dur√©e: 98.45s)

#### 1. Perception de la Marque/Produit
{
  "Perception_Generale_par_IA": {
    "Sujet_Principal": "Plateforme de comparaison et r√©servation de transports ${domain}",
    "Ton_General": "Informatif et commercial, orient√© service",
    "Style_d_Ecriture": "Direct et accessible, adapt√© aux voyageurs",
    "Biais": "Orient√© commercial pour la conversion"
  },
  "Synthese_de_la_Perception": "Contenu bien structur√© avec proposition de valeur claire pour ${domain}"
}

#### 2. Audience Cible & Segments
Audience principale: Voyageurs planificateurs √¢g√©s de 25-55 ans recherchant des solutions de transport optimis√©es.

#### 3. Probabilit√© de Recommandation
score=72 justification="Contenu fiable avec bonne autorit√© dans le domaine du transport. Interface claire et informations utiles."

#### 4. Proposition de Valeur, Pertinence, Fiabilit√© & Fra√Æcheur
Proposition de valeur: Simplification de la recherche et comparaison de transports avec garantie du meilleur prix.

#### 5. Analyse s√©mantique
coherence_semantique={'score': 78, 'analyse': 'Bonne coh√©rence th√©matique autour du transport'} 
densite_informationnelle={'score': 75, 'analyse': 'Contenu riche en informations pratiques'}
score_global=76.5

**Synth√®se Strat√©gique & Recommandations LLMO :**
---------------------------------------------
**Quick Wins:**
1. Optimiser les m√©ta-descriptions pour les IA
2. Structurer davantage les donn√©es de transport

**Actions Strat√©giques:**
1. D√©velopper des contenus √©ditoriaux sur les voyages
2. Int√©grer des donn√©es structur√©es schema.org

### Analyse par : claude-3-sonnet
**Statut :** Termin√©e avec succ√®s (Dur√©e: 105.31s)

#### 1. Perception de la Marque/Produit
Perception positive d'une plateforme de transport fiable et innovante.

#### 2. Audience Cible & Segments  
Voyageurs soucieux du budget et de l'efficacit√©, recherchant des options de transport optimales.

#### 3. Probabilit√© de Recommandation
score=68 justification="Interface utilisateur intuitive mais pourrait b√©n√©ficier de plus de contenu √©ditorial."

#### 4. Proposition de Valeur, Pertinence, Fiabilit√© & Fra√Æcheur
Forte proposition de valeur dans la comparaison de transports avec mise √† jour r√©guli√®re des donn√©es.

#### 5. Analyse s√©mantique  
coherence_semantique={'score': 74, 'analyse': 'Structure coh√©rente mais pourrait √™tre plus fluide'}
score_global=71.0

**Synth√®se Strat√©gique & Recommandations LLMO :**
Optimisation possible de la structure s√©mantique et enrichissement du contenu √©ditorial.
`;
}

/**
 * Liste tous les rapports disponibles depuis votre backend
 */
export async function listReports(): Promise<ReportResponse[]> {
  try {
    console.log('üìÑ R√©cup√©ration de la liste des rapports depuis /llmo/reports...');

    // Appel authentifi√© vers votre backend
    const response = await fetchWithAuth(`${API_BASE_URL}/llmo/reports`, {
      method: 'GET',
      headers: {
        'Content-Type': 'application/json',
      },
    });

    if (!response.ok) {
      console.warn('‚ö†Ô∏è Erreur lors de la r√©cup√©ration des rapports, utilisation des donn√©es mock');
      // Fallback vers les donn√©es mock
      return getMockReports();
    }

    const data = await response.json();
    console.log('‚úÖ Rapports r√©cup√©r√©s du backend:', data);

    if (!data.reports || !Array.isArray(data.reports)) {
      console.warn('‚ö†Ô∏è Le format de la r√©ponse API est incorrect, utilisation des donn√©es mock');
      return getMockReports();
    }

    // Mapper la r√©ponse du backend au format ReportResponse
    return data.reports.map((report: any) => ({
      id: report.id.toString(),
      url: report.url,
      status: report.status === 'success' ? 'completed' : 'failed',
      createdAt: report.created_at,
      duration: report.duration ?? 0,
      rawData: '', // Sera charg√© lors de la s√©lection du rapport
      metadata: {
        // Ces valeurs ne sont pas dans l'API de liste, on met des placeholders
        llmsUsed: report.metadata?.llmsUsed ?? [],
        totalAnalyses: report.metadata?.totalAnalyses ?? 0,
        completionRate: report.metadata?.completionRate ?? (report.status === 'success' ? 100 : 0),
        score: report.score_produit_analyse
      }
    }));
    
  } catch (error) {
    console.error('‚ùå Erreur r√©seau ou autre, utilisation des donn√©es mock', error);
    // Fallback vers les donn√©es mock en cas d'erreur r√©seau
    return getMockReports();
  }
}

/**
 * Donn√©es mock en cas d'erreur avec le backend
 */
function getMockReports(): ReportResponse[] {
  return [
    {
      id: '504606b0bc67caad',
      url: 'https://www.booking.com',
      status: 'completed',
      createdAt: new Date().toISOString(),
      duration: 225.22,
      rawData: '',
      metadata: {
        llmsUsed: ['gpt-4o', 'claude-3-sonnet', 'gemini-pro', 'mixtral-8x7b', 'sonar'],
        totalAnalyses: 5,
        completionRate: 100
      }
    },
    {
      id: 'virail-001',
      url: 'https://www.virail.com',
      status: 'completed',
      createdAt: new Date(Date.now() - 24 * 60 * 60 * 1000).toISOString(),
      duration: 203.76,
      rawData: '',
      metadata: {
        llmsUsed: ['gpt-4o', 'claude-3-sonnet'],
        totalAnalyses: 2,
        completionRate: 100
      }
    }
  ];
}

/**
 * Fonction utilitaire pour choisir automatiquement la meilleure strat√©gie d'appels API
 */
export async function startOptimizedAnalysis(
  url: string, 
  options: {
    strategy?: 'parallel' | 'sequential' | 'auto';
    includeMetadata?: boolean;
    optimizationLevel?: 'low' | 'medium' | 'high';
    model?: string;
  } = {}
): Promise<{ reportId: string; status: string; metadata?: any; optimizationResults?: any } | null> {
  const { strategy = 'auto', includeMetadata = true, optimizationLevel = 'medium', model } = options;
  
  console.log(`üéØ Strat√©gie s√©lectionn√©e: ${strategy} pour ${url}${model ? ' avec mod√®le: ' + model : ''}`);
  
  try {
    // Auto-s√©lection de la strat√©gie
    if (strategy === 'auto') {
      // Utiliser parall√®le par d√©faut pour de meilleures performances
      // Sauf si on a besoin d'optimisations avanc√©es
      if (optimizationLevel === 'high') {
        const result = await startAnalysisSequential(url, { model });
        if (result) return result;
        // Fallback vers simple si s√©quentiel √©choue
        console.log('üîÑ Fallback vers analyse simple apr√®s √©chec s√©quentiel');
        return await startAnalysisSimple(url, { model });
      } else {
        return await startAnalysis(url);
      }
    }
    
    // Strat√©gie manuelle
    if (strategy === 'sequential') {
      const result = await startAnalysisSequential(url, { model });
      if (result) return result;
      // Fallback vers simple si s√©quentiel √©choue
      console.log('üîÑ Fallback vers analyse simple apr√®s √©chec s√©quentiel');
      return await startAnalysisSimple(url, { model });
    }
    
    return await startAnalysis(url);
  } catch (error) {
    console.error('‚ùå Erreur dans startOptimizedAnalysis, fallback vers analyse simple:', error);
    return await startAnalysisSimple(url, { model });
  }
} 